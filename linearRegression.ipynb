{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c56f936",
   "metadata": {},
   "source": [
    "# Predicting Match Attendance using Linear Regression\n",
    "\n",
    "**What is Linear Regression?**  \n",
    "Linear regression models the relationship between one continuous dependent variable (target) and one or more independent variables (features), assuming a linear relationship.\n",
    "\n",
    "**Why use it?**  \n",
    "- For predicting a continuous outcome.\n",
    "- Provides interpretable coefficients indicating the average change in attendance per unit change in each feature.\n",
    "- Helps quantify and compare the influence of different factors.\n",
    "\n",
    "**Outputs:**  \n",
    "- Predicted values for the target variable.\n",
    "- RMSE (Root Mean Squared Error) for evaluating prediction accuracy.\n",
    "- Model coefficients showing the magnitude and direction of each feature’s effect on the target value.\n",
    "\n",
    "**Why analyze weather and match-related effects on attendance?**\n",
    "Understanding these drivers supports data-driven decisions:\n",
    "1. Stadium operations: Adjust staffing, concessions, and security based on expected turnout under varying weather.\n",
    "2. Facility preparedness: Plan for weather-related infrastructure needs (e.g., covering stands, heating) to maintain fan comfort and safety.\n",
    "3. Marketing & promotions: Time special offers or dynamic pricing on days with predicted low attendance due to adverse conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e7b69",
   "metadata": {},
   "source": [
    "## 1. Imports and Data Sources\n",
    "\n",
    "Import necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "737b4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a2b47",
   "metadata": {},
   "source": [
    "## 2. Build the Combined Dataset\n",
    "\n",
    "Load your datasets, and merge the important tables into a single DataFrame for easier feature engineering and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e46fa2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this data import with your real data.\n",
    "# In the weather table, we want to keep 'None' values as an own category in the column\n",
    "# 'precipitation', which is why we need the addition.\n",
    "df_match        = pd.read_csv('match_table.csv')\n",
    "df_weather      = pd.read_csv('weather_table.csv', na_values=[], keep_default_na=False)\n",
    "df_stadium      = pd.read_csv('stadium_table.csv')\n",
    "\n",
    "df = (\n",
    "    df_match\n",
    "      .merge(df_weather, on='match_id', how='left')\n",
    "      .merge(df_stadium[['stadium_id', 'capacity']],  on='stadium_id',  how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2371e",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create new features that are not directly available in the raw data.  \n",
    "Example: Calculate the stadion attendance in percentage from the absolute numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a17c7704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   attendance_in_percent\n",
      "0                  66.15\n",
      "1                  94.10\n",
      "2                  52.10\n",
      "3                  72.27\n",
      "4                  87.02\n"
     ]
    }
   ],
   "source": [
    "df['attendance_in_percent'] = (df['attendance'] / df['capacity'] * 100).round(2)\n",
    "\n",
    "# Test if the values have been computed correctly.\n",
    "print(df[['attendance_in_percent']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b71cb37",
   "metadata": {},
   "source": [
    "## 4. Select and Split Features and Target\n",
    "\n",
    "Choose the predictor variables and the target variable.\n",
    "\n",
    "Create a separate copy of the selected columns to avoid modifying the original DataFrame `df`. This is important when performing transformations (e.g., scaling) that shouldn't affect `df`.\n",
    "\n",
    "Finally, separate features (X) and target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "42b6487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'features' to include whatever predictors you need.\n",
    "model_columns = [\n",
    "    \"temperature\",\n",
    "    \"conditions\",\n",
    "    \"humidity\",\n",
    "    \"precipitation\",\n",
    "    \"wind_speed_in_km_h\",\n",
    "    \"attendance_in_percent\"   # target: in percent.\n",
    "]\n",
    "\n",
    "model_df = df[model_columns].copy()\n",
    "\n",
    "X = model_df.drop(columns=\"attendance_in_percent\")\n",
    "y = model_df[\"attendance_in_percent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc31ee",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split\n",
    "\n",
    "Split the data into training and testing sets to train the model on one portion and evaluate its performance on unseen data.\n",
    "\n",
    "You can adjust 'test_size' to control how much data goes into the test set. Common values range from 0.2 to 0.3 (i.e., 20–30% of the data used for testing).\n",
    "The 'random_state' ensures reproducibility: using the same value will yield the same split every time. You can choose any integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d6eca0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7131d73",
   "metadata": {},
   "source": [
    "## 6. Encode Categorical Features\n",
    "\n",
    "Many machine learning models cannot handle categorical variables directly.\n",
    "One-Hot-Encoding transforms a categorical feature (e.g., \"conditions\" and \"precipitation\") into multiple binary (0/1) features — one for each category, indicating whether a sample belongs to that category.\n",
    "This allows the model to learn a separate coefficient for each category.\n",
    "\n",
    "When One-Hot-Encoding is applied, the first column is dropped and becomes the baseline. All coefficients of the remaining categories will be interpreted in relation to this dropped base category.\n",
    "\n",
    "Repeat the following steps for every categorical column you have among your predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7081c490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All conditions in the dataset:\n",
      "['Cloudy' 'Fog' 'Rain' 'Snow' 'Sunny' 'Windy']\n",
      "All precipitations in the dataset:\n",
      "['Drizzle' 'Hail' 'None' 'Rain' 'Snow']\n",
      "\n",
      "Reference (baseline) position used for comparison: Sunny\n",
      "\n",
      "Reference (baseline) position used for comparison: None\n"
     ]
    }
   ],
   "source": [
    "# Show all categories to decide which to drop.\n",
    "print(\"All conditions in the dataset:\")\n",
    "print(np.sort(df['conditions'].unique()))\n",
    "\n",
    "print(\"All precipitations in the dataset:\")\n",
    "print(np.sort(df['precipitation'].unique()))\n",
    "\n",
    "# Apply One-Hot-Encoding to the 'conditions' and 'precipitation' column.\n",
    "# Choose in the 'drop' argument which category you want to use as the reference category\n",
    "# (the first is for the first column and the second for the second column).\n",
    "encoder = OneHotEncoder(drop=['Sunny', 'None'], sparse_output=False)\n",
    "encoder.fit(X_train[['conditions', 'precipitation']])\n",
    "pos_cols = encoder.get_feature_names_out(['conditions', 'precipitation'])\n",
    "X_train_cons_pres = pd.DataFrame(\n",
    "    encoder.transform(X_train[['conditions', 'precipitation']]),\n",
    "    columns=pos_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cons_pres = pd.DataFrame(\n",
    "    encoder.transform(X_test[['conditions', 'precipitation']]),\n",
    "    columns=pos_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Show which category was dropped (baseline) for interpretation later.\n",
    "reference_condition = list(set(df['conditions'].unique()) - set([col.split(\"_\")[1] for col in pos_cols]))\n",
    "print(f\"\\nReference (baseline) position used for comparison: {reference_condition[0]}\")\n",
    "\n",
    "reference_precipitation= list(set(df['precipitation'].unique()) - set([col.split(\"_\")[1] for col in pos_cols]))\n",
    "print(f\"\\nReference (baseline) position used for comparison: {reference_precipitation[0]}\")\n",
    "\n",
    "# Remove original 'conditions' and 'precipitation' column and append the dummies that have just been created.\n",
    "X_train = pd.concat([X_train.drop(columns=['conditions', 'precipitation']), X_train_cons_pres], axis=1)\n",
    "X_test  = pd.concat([X_test.drop(columns=['conditions', 'precipitation']), X_test_cons_pres],  axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a4fdf",
   "metadata": {},
   "source": [
    "## 7. Scale Numeric Features\n",
    "\n",
    "Standardize numeric columns so they have mean = 0 and standard deviation = 1. This is important because many machine learning models are sensitive to feature scales. Features with larger ranges can dominate the model's learning process.\n",
    "Standardization ensures that each feature contributes equally to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "751fc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'temperature',\n",
    "    'humidity',\n",
    "    'wind_speed_in_km_h'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numeric_cols])\n",
    "X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols]  = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941d2c1",
   "metadata": {},
   "source": [
    "## 8. Train Linear Regression Model\n",
    "\n",
    "Train linear regression on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "15cdc41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efec0a",
   "metadata": {},
   "source": [
    "## 9. Make Predictions and Evaluate Performance\n",
    "\n",
    "Predict the target variable values on the test set and evaluate the model accuracy.\n",
    "\n",
    "- y_pred contains the predicted continuous values (in this case: attendance percentages) from the model.\n",
    "- The Mean Squared Error (MSE) is computed to measure the average squared difference between actual and predicted values.\n",
    "- The Root Mean Squared Error (RMSE) is computed as the square root of MSE, providing an interpretable error metric in the same units as the target variable.\n",
    "\n",
    "This evaluation helps us understand how well the model predicts attendance and how large the typical prediction errors are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0889013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE     : 15.17\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse    = mean_squared_error(y_test, y_pred)\n",
    "rmse   = np.sqrt(mse)\n",
    "print(f\"RMSE     : {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa7026",
   "metadata": {},
   "source": [
    "## 10. Interpret Model Coefficients\n",
    "\n",
    "Coefficients show how each feature affects the target variable (here: match attendance) in a linear way.\n",
    "\n",
    "- Numeric features (e.g., 'temperature', 'humidity'), indicate the change in attendance in percent per unit increase. Example: A coefficient of 0.95 for temperature means that for each additional degree, attendance increases by ~0.95 percentage points, assuming all other variables stay constant.\n",
    "- Categorical features (e.g., 'conditions_Cloudy', 'precipitation_Rain') are interpreted relative to the baseline category (for 'conditions': 'Sunny', and for 'precipitation': 'None'). A negative coefficient means lower attendance compared to the reference, while a positive one means higher attendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e6394d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature impacts on attendance:\n",
      "                  feature  coefficient\n",
      "3       conditions_Cloudy     5.246340\n",
      "9      precipitation_Hail     4.619206\n",
      "5         conditions_Rain     3.612750\n",
      "8   precipitation_Drizzle     3.574786\n",
      "7        conditions_Windy     3.265041\n",
      "4          conditions_Fog     2.752692\n",
      "6         conditions_Snow     2.647916\n",
      "11     precipitation_Snow     2.481612\n",
      "1                humidity     1.767599\n",
      "0             temperature     0.945195\n",
      "2      wind_speed_in_km_h    -0.306377\n",
      "10     precipitation_Rain    -0.524757\n"
     ]
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    \"feature\":    X_train.columns,\n",
    "    \"coefficient\": model.coef_\n",
    "}).sort_values(by=\"coefficient\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature impacts on attendance:\")\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f846d6",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "Reference for 'conditions': 'Sunny'.  \n",
    "Reference for 'precipitation': 'None'.\n",
    "\n",
    "- Concerning the conditions, cloudy weather shows the highest positive impact on attendance.\n",
    "- Surprisingly, on days with conditions like rain, wind, fog and snow, the attendance also seems to be higher than on sunny days.  \n",
    "\n",
    "  \n",
    "- Regarding the precipitation, a similar effect shows. The precipitation types like hail, drizzle and snow are also associated with higher attendance than days without precipitation.\n",
    "- Rain is the only precipitation type with a negative impact. \n",
    " \n",
    "\n",
    "- Higher humidity and temperature slightly increase attendance, reflecting preference for warmer and more humid days.\n",
    "- Wind speed has a small negative effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
